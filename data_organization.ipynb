{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df4ba16",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Sanity check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40a0834c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amar/Desktop/projects/nfs_object_detection\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40d6d662",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amar/Desktop/projects/nfs_object_detection/env/bin/python\n"
     ]
    }
   ],
   "source": [
    "! which python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8dc44b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c244074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import shutil\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d5d1cb",
   "metadata": {},
   "source": [
    "# Paths and files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cd9a38d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_dir = os.getcwd()\n",
    "paths = {\n",
    "    'raw_video': os.path.join(os.getcwd(),'data','raw','videos'),\n",
    "    'raw_image' : os.path.join(os.getcwd(),'data','raw','images'),\n",
    "    'processed_video': os.path.join(os.getcwd(),'data','processed','videos'),\n",
    "    'processed_image' : os.path.join(os.getcwd(),'data','processed','images'),\n",
    "    'yolov3_tiny_config': os.path.join(project_dir, 'my_models', 'yolov3_tiny', 'yolov3_tiny.cfg'), \n",
    "    'yolov3_tiny_weights': os.path.join(project_dir, 'my_models', 'yolov3_tiny', 'yolov3_tiny.weights'),\n",
    "    'yolov3_tiny_model': os.path.join(project_dir, 'my_models', 'yolov3_tiny', 'yolov3_tiny.h5'),\n",
    "    'yolov3_320_config': os.path.join(project_dir, 'my_models', 'yolov3_320', 'yolov3_320.cfg'), \n",
    "    'yolov3_320_weights': os.path.join(project_dir, 'my_models', 'yolov3_320', 'yolov3_320.weights'),\n",
    "    'yolov3_320_model': os.path.join(project_dir, 'my_models', 'yolov3_320', 'yolov3_320.h5'),\n",
    "    'labels_dir': os.path.join(project_dir, 'data', 'labels'),\n",
    "    'images_dir': os.path.join(project_dir, 'data', 'images'),\n",
    "    'final_imgs_labels_dir': os.path.join(project_dir, 'colab', 'data', 'obj'),\n",
    "    'colab_train.txt': os.path.join(project_dir, 'colab', 'data', 'train.txt'),\n",
    "    'colab_test.txt': os.path.join(project_dir, 'colab', 'data', 'test.txt')\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32328cb",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Video to image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fbbec920",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_video_path = os.path.join(paths['raw_video'], 'video3.avi')\n",
    "output_image_dir = os.path.join(paths['raw_image'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "51c65f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video not read, exiting..\n"
     ]
    }
   ],
   "source": [
    "#* Save the frames needed in the set wanted_frames\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "count = 0\n",
    "total_frames = cap.get(7)\n",
    "# print(total_frames)\n",
    "wanted_frames = set()\n",
    "try:\n",
    "   while True:\n",
    "      ret, frame = cap.read()\n",
    "      cv2.imshow('Input Video', frame)\n",
    "      if cv2.waitKey(0) == ord('k'):\n",
    "         wanted_frames.add(count)\n",
    "      elif cv2.waitKey(0) == ord('q'):\n",
    "         break\n",
    "      count += 1\n",
    "except:\n",
    "   # print(count)\n",
    "   print('Video not read, exiting..')\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "# print('wanted_frames:', wanted_frames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fe3a67bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8412\n"
     ]
    }
   ],
   "source": [
    "print(len(wanted_frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c22dabc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#* Save every 20th frame from the wanted_frames set\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "count = 0\n",
    "kept = 0\n",
    "try:\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        cv2.imshow('Input Video', frame)\n",
    "        if count in wanted_frames:\n",
    "            kept += 1\n",
    "            if kept % 20 == 0:\n",
    "                cv2.imwrite(os.path.join(output_image_dir, str(count) + '.jpg'), frame)\n",
    "        if cv2.waitKey(10) == ord('q'):\n",
    "            break\n",
    "        count += 1\n",
    "except Exception as e:\n",
    "    cv2.destroyAllWindows()\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0652a7-c876-46a5-8936-6995feeee74f",
   "metadata": {},
   "source": [
    "# Colab Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "962838b9-6602-42ed-8936-7d9b9af87f08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_video': '/home/amar/Desktop/projects/nfs_object_detection/data/raw/videos',\n",
       " 'raw_image': '/home/amar/Desktop/projects/nfs_object_detection/data/raw/images',\n",
       " 'processed_video': '/home/amar/Desktop/projects/nfs_object_detection/data/processed/videos',\n",
       " 'processed_image': '/home/amar/Desktop/projects/nfs_object_detection/data/processed/images',\n",
       " 'yolov3_tiny_config': '/home/amar/Desktop/projects/nfs_object_detection/my_models/yolov3_tiny/yolov3_tiny.cfg',\n",
       " 'yolov3_tiny_weights': '/home/amar/Desktop/projects/nfs_object_detection/my_models/yolov3_tiny/yolov3_tiny.weights',\n",
       " 'yolov3_tiny_model': '/home/amar/Desktop/projects/nfs_object_detection/my_models/yolov3_tiny/yolov3_tiny.h5',\n",
       " 'yolov3_320_config': '/home/amar/Desktop/projects/nfs_object_detection/my_models/yolov3_320/yolov3_320.cfg',\n",
       " 'yolov3_320_weights': '/home/amar/Desktop/projects/nfs_object_detection/my_models/yolov3_320/yolov3_320.weights',\n",
       " 'yolov3_320_model': '/home/amar/Desktop/projects/nfs_object_detection/my_models/yolov3_320/yolov3_320.h5',\n",
       " 'labels_dir': '/home/amar/Desktop/projects/nfs_object_detection/data/labels',\n",
       " 'images_dir': '/home/amar/Desktop/projects/nfs_object_detection/data/images',\n",
       " 'final_imgs_labels_dir': '/home/amar/Desktop/projects/nfs_object_detection/colab/data/obj'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paths"
   ]
  },
  {
   "cell_type": "raw",
   "id": "340bcf14-9bad-4313-aa31-a14c71d6bdda",
   "metadata": {},
   "source": [
    "Follow along the youtube video.\n",
    "We need to create some files and directories.\n",
    "Done 1. colab/data/obj dir that will have the images, labels with the same names different extensions.\n",
    "2. train.txt will contain the path to all the images that are to be used as training\n",
    "3. test.txt will contain the path to all the images that are to be used in testing/validation\n",
    "Done 4. obj.data file that contains information about (num_classes, train.txt path, test.txt path, obj.names path, backup)\n",
    "Done 5. obj.names file that contains class names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08d4fe1a-be65-4f9c-99c2-0ea6159a1528",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Storing the labels and images in a list to see which of the images were not labelled\n",
    "labels = list()\n",
    "images = list()\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(paths['labels_dir']):\n",
    "    for file in filenames:\n",
    "        labels.append(file[0:-4])\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(paths['images_dir']):\n",
    "    for file in filenames:\n",
    "        images.append(file[0:-4])\n",
    "\n",
    "labels = set(labels)\n",
    "images = set(images)\n",
    "\n",
    "# Find the ones that are common\n",
    "images_and_labels = labels.intersection(images)\n",
    "len(images_and_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84604804-83f1-449e-9b42-38158f684799",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## colab/data/obj folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29d55683-51a2-4ed6-9f5c-b5d622589ad5",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 files done\n",
      "1 files done\n",
      "2 files done\n",
      "3 files done\n",
      "4 files done\n",
      "5 files done\n",
      "6 files done\n",
      "7 files done\n",
      "8 files done\n",
      "9 files done\n",
      "10 files done\n",
      "11 files done\n",
      "12 files done\n",
      "13 files done\n",
      "14 files done\n",
      "15 files done\n",
      "16 files done\n",
      "17 files done\n",
      "18 files done\n",
      "19 files done\n",
      "20 files done\n",
      "21 files done\n",
      "22 files done\n",
      "23 files done\n",
      "24 files done\n",
      "25 files done\n",
      "26 files done\n",
      "27 files done\n",
      "28 files done\n",
      "29 files done\n",
      "30 files done\n",
      "31 files done\n",
      "32 files done\n",
      "33 files done\n",
      "34 files done\n",
      "35 files done\n",
      "36 files done\n",
      "37 files done\n",
      "38 files done\n",
      "39 files done\n",
      "40 files done\n",
      "41 files done\n",
      "42 files done\n",
      "43 files done\n",
      "44 files done\n",
      "45 files done\n",
      "46 files done\n",
      "47 files done\n",
      "48 files done\n",
      "49 files done\n",
      "50 files done\n",
      "51 files done\n",
      "52 files done\n",
      "53 files done\n",
      "54 files done\n",
      "55 files done\n",
      "56 files done\n",
      "57 files done\n",
      "58 files done\n",
      "59 files done\n",
      "60 files done\n",
      "61 files done\n",
      "62 files done\n",
      "63 files done\n",
      "64 files done\n",
      "65 files done\n",
      "66 files done\n",
      "67 files done\n",
      "68 files done\n",
      "69 files done\n",
      "70 files done\n",
      "71 files done\n",
      "72 files done\n",
      "73 files done\n",
      "74 files done\n",
      "75 files done\n",
      "76 files done\n",
      "77 files done\n",
      "78 files done\n",
      "79 files done\n",
      "80 files done\n",
      "81 files done\n",
      "82 files done\n",
      "83 files done\n",
      "84 files done\n",
      "85 files done\n",
      "86 files done\n",
      "87 files done\n",
      "88 files done\n",
      "89 files done\n",
      "90 files done\n",
      "91 files done\n",
      "92 files done\n",
      "93 files done\n",
      "94 files done\n",
      "95 files done\n",
      "96 files done\n",
      "97 files done\n",
      "98 files done\n",
      "99 files done\n",
      "100 files done\n",
      "101 files done\n",
      "102 files done\n",
      "103 files done\n",
      "104 files done\n",
      "105 files done\n",
      "106 files done\n",
      "107 files done\n",
      "108 files done\n",
      "109 files done\n",
      "110 files done\n",
      "111 files done\n",
      "112 files done\n",
      "113 files done\n",
      "114 files done\n",
      "115 files done\n",
      "116 files done\n",
      "117 files done\n",
      "118 files done\n",
      "119 files done\n",
      "120 files done\n",
      "121 files done\n",
      "122 files done\n",
      "123 files done\n",
      "124 files done\n",
      "125 files done\n",
      "126 files done\n",
      "127 files done\n",
      "128 files done\n",
      "129 files done\n",
      "130 files done\n",
      "131 files done\n",
      "132 files done\n",
      "133 files done\n",
      "134 files done\n",
      "135 files done\n",
      "136 files done\n",
      "137 files done\n",
      "138 files done\n",
      "139 files done\n",
      "140 files done\n",
      "141 files done\n",
      "142 files done\n",
      "143 files done\n",
      "144 files done\n",
      "145 files done\n",
      "146 files done\n",
      "147 files done\n",
      "148 files done\n",
      "149 files done\n",
      "150 files done\n",
      "151 files done\n",
      "152 files done\n",
      "153 files done\n",
      "154 files done\n",
      "155 files done\n",
      "156 files done\n",
      "157 files done\n",
      "158 files done\n",
      "159 files done\n",
      "160 files done\n",
      "161 files done\n",
      "162 files done\n",
      "163 files done\n",
      "164 files done\n",
      "165 files done\n",
      "166 files done\n",
      "167 files done\n",
      "168 files done\n",
      "169 files done\n",
      "170 files done\n",
      "171 files done\n",
      "172 files done\n",
      "173 files done\n",
      "174 files done\n",
      "175 files done\n",
      "176 files done\n",
      "177 files done\n",
      "178 files done\n",
      "179 files done\n",
      "180 files done\n",
      "181 files done\n",
      "182 files done\n",
      "183 files done\n",
      "184 files done\n",
      "185 files done\n",
      "186 files done\n",
      "187 files done\n",
      "188 files done\n",
      "189 files done\n",
      "190 files done\n",
      "191 files done\n",
      "192 files done\n",
      "193 files done\n",
      "194 files done\n",
      "195 files done\n",
      "196 files done\n",
      "197 files done\n",
      "198 files done\n",
      "199 files done\n",
      "200 files done\n",
      "201 files done\n",
      "202 files done\n",
      "203 files done\n",
      "204 files done\n",
      "205 files done\n",
      "206 files done\n",
      "207 files done\n",
      "208 files done\n",
      "209 files done\n",
      "210 files done\n",
      "211 files done\n",
      "212 files done\n",
      "213 files done\n",
      "214 files done\n",
      "215 files done\n",
      "216 files done\n",
      "217 files done\n",
      "218 files done\n",
      "219 files done\n",
      "220 files done\n",
      "221 files done\n",
      "222 files done\n",
      "223 files done\n",
      "224 files done\n",
      "225 files done\n",
      "226 files done\n",
      "227 files done\n",
      "228 files done\n",
      "229 files done\n",
      "230 files done\n",
      "231 files done\n",
      "232 files done\n",
      "233 files done\n",
      "234 files done\n",
      "235 files done\n",
      "236 files done\n",
      "237 files done\n",
      "238 files done\n",
      "239 files done\n",
      "240 files done\n",
      "241 files done\n",
      "242 files done\n",
      "243 files done\n",
      "244 files done\n",
      "245 files done\n",
      "246 files done\n",
      "247 files done\n",
      "248 files done\n",
      "249 files done\n",
      "250 files done\n",
      "251 files done\n",
      "252 files done\n",
      "253 files done\n",
      "254 files done\n",
      "255 files done\n",
      "256 files done\n",
      "257 files done\n",
      "258 files done\n",
      "259 files done\n",
      "260 files done\n",
      "261 files done\n",
      "262 files done\n",
      "263 files done\n",
      "264 files done\n",
      "265 files done\n",
      "266 files done\n",
      "267 files done\n",
      "268 files done\n",
      "269 files done\n",
      "270 files done\n",
      "271 files done\n",
      "272 files done\n",
      "273 files done\n",
      "274 files done\n",
      "275 files done\n",
      "276 files done\n",
      "277 files done\n",
      "278 files done\n",
      "279 files done\n",
      "280 files done\n",
      "281 files done\n",
      "282 files done\n",
      "283 files done\n",
      "284 files done\n",
      "285 files done\n",
      "286 files done\n",
      "287 files done\n",
      "288 files done\n",
      "289 files done\n",
      "290 files done\n",
      "291 files done\n",
      "292 files done\n",
      "293 files done\n",
      "294 files done\n",
      "295 files done\n",
      "296 files done\n",
      "297 files done\n",
      "298 files done\n",
      "299 files done\n",
      "300 files done\n",
      "301 files done\n",
      "302 files done\n",
      "303 files done\n",
      "304 files done\n",
      "305 files done\n",
      "306 files done\n",
      "307 files done\n",
      "308 files done\n",
      "309 files done\n",
      "310 files done\n",
      "311 files done\n",
      "312 files done\n",
      "313 files done\n",
      "314 files done\n",
      "315 files done\n",
      "316 files done\n",
      "317 files done\n",
      "318 files done\n",
      "319 files done\n",
      "320 files done\n",
      "321 files done\n",
      "322 files done\n",
      "323 files done\n",
      "324 files done\n",
      "325 files done\n",
      "326 files done\n",
      "327 files done\n",
      "328 files done\n",
      "329 files done\n",
      "330 files done\n",
      "331 files done\n",
      "332 files done\n",
      "333 files done\n",
      "334 files done\n"
     ]
    }
   ],
   "source": [
    "for i, image_id in enumerate(images_and_labels):\n",
    "    img_src_path = os.path.join(paths['images_dir'], image_id + '.jpg')\n",
    "    label_src_path = os.path.join(paths['labels_dir'], image_id + '.txt')\n",
    "    dst_path = os.path.join(project_dir, 'colab', 'data', 'obj')\n",
    "    shutil.copy(img_src_path, dst_path)\n",
    "    shutil.copy(label_src_path, dst_path)\n",
    "    print('{} files done'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a703c3c-7c7d-409f-8f24-130fc8986a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/amar/Desktop/projects/nfs_object_detection/colab/data/obj 0 670\n"
     ]
    }
   ],
   "source": [
    "for dirpath, dirnames, filenames in os.walk(paths['final_imgs_labels_dir']):\n",
    "    print(dirpath, len(dirnames), len(filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a00e7f49-3307-4c7c-8576-2f81d5e3a8d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Train and Test .txt files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f3594c4-6037-4b42-89f2-fcb5e5d00590",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "335"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(images_and_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7aed0c37-f625-4af3-aa18-45a303cf8d01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40, 295, 0.11940298507462686)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = set(random.sample(images_and_labels, 40))\n",
    "train = images_and_labels - test\n",
    "len(test), len(train), len(test)/(len(test) + len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ac0aef93-dfa1-44eb-9597-70afbee4497a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths['colab_test.txt'], 'w') as f:\n",
    "    for test_image in test:\n",
    "        f.write(os.path.join('data/obj/' + test_image + '.jpg' + '\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05b33a4c-bb5c-45ef-94cb-831853eb8997",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(paths['colab_train.txt'], 'w') as f:\n",
    "    for train_image in train:\n",
    "        f.write(os.path.join('data/obj/' + train_image + '.jpg' + '\\n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1196acd-3b93-4cb8-a8fe-b9c32765dd42",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a52458-e1c9-422b-b9ab-d9f6eefd7d4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "514b12dd9e895721febb44556d1c6e815f8bc4476ace6b94922a62cfbe60c967"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
